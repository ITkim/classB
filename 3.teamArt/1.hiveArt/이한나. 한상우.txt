이한나 한상우 조 


1. hdfs dfs -cp test1.csv /user/hive/warehouse에 넣었는데 test1.csv가 dir로 바뀌어서 저장된 것을 확인. 

>>그래서 hdfs dfs -put test1.csv /user/hive/warehouse에 put으로 넣었더니 파일로 들어감.  둘의 차이점을 알게 됨. 


2. vi test1.csv 를 만듬. 
하둡에 넣으려고 hdfs dfs -put test1.csv /user/hive/warehouse(/) (/)는 /존재 필요성 여부를 파악.>> 있으나 마나 똑같음. 


3. 1. test1.csv 파일과 test2.txt 파일을 만듬. 
   2. 하둡에 test table을 생성함 
   3. hive >> select * from test를 실행. >> test 결과 잘 나옴.
   4. 하둡에 test2 table을 생성함. 
   5. hive >> select * from test2를 실행 >> test2 결과 안나옴 >> test와 test2 내용이 같이 합쳐져서 출력됨. 

   ***시사점***

 하나의 warehouse 디렉토리에 test,test2 구분해서 넣었지만 하나로 인식함. 
 블록 파티션에 정보를 나누는 어떤 기술이 있지만 아직 배우지 않음. 


4. drop table test를 했더니 warehouse 디렉터리가 없어짐.. 이유는 알 수 없음. 고민을 해봐야 될 것 같습니다. 


5. 3번에 하였던 방식으로 진행 test3.csv와 test.csv 만듬.  테이블은 create external 로 만듬.  
   drop table test3을 했을 때 select * from test4를 했을 때 내용이 다 나왔음. 

BUT drop table test4을 했을 때 select * from test4의 결과는 test4를 찾을 수 없다고 나옴.

그래서 external 썻을 때와 아닐 때 차이점은 external 쓰면 한개를 지워도 내용이 남아있고 
두개를 지워야만 다 내용이 사라짐.  external 했을 때 warehouse 디렉토리는 사라지지 않았음. 

external 안했을 때 하나만 지웠을 경우에는 내용이 둘 다 사라짐. 


이상입니다. 감사합니다 ^^ 
 

  